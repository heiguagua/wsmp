#Spring默认线程池的大小
spring.thread.poolSize=100

#kafka消费者数量,和消费的分区数一致
kafka.consumer.count=1

#配置kafka的集群地址
kafka.consumer.bootstrap.servers=192.168.13.151:6667,192.168.13.152:6667,192.168.13.151:6667
kafka.consumer.topic=wsmp
kafka.consumer.group.id=wsmp

#kafkavalue解码类
kafka.value.deserializer=com.chinawiserv.kafka.KafkaObjDeserializer
#最大消息队列深度
kafka.consumer.queueDepth=100
#暂停消费的时长（单位:毫秒）
kafka.consumer.pausemilliseconds=30000

#客户端接收消息的缓冲区大小 512MB
kafka.consumer.receive.buffer.bytes=536870912
#每个分区最大拉去大小 3MB
kafka.consumer.max.partition.fetch.bytes=3145728

#配置kafka的是否自动提交消费的状态
kafka.consumer.enable.auto.commit=false

#配置Hbase相关参数
hbase.zookeeper.quorum=192.168.13.151,192.168.13.152,192.168.13.154
hbase.zookeeper.property.clientPort=2181
hbase.zookeeper.znode.parent=/hbase-unsecure
hbase.tableName=wsmp

#配置MongoDB相关参数
mongodb.hosts=192.168.13.151:30000,192.168.13.152:30000,192.168.13.154:30000
mongodb.db=wsmp
mongodb.shard.enable=true

#hbase开关
datahandler.hbase.enable=false

#实时分析开关
datahandler.mongoflush.enable=false

#实时查询结果分析开关
datahandler.mongostream.enable=false

#WebSocket地址
websocket.host=ws://192.168.13.150:8081/wsmp

#配置日志
logging.config=classpath:logback-spring.xml
logging.path=logs


